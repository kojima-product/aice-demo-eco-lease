"""
Streamlit Demo App - AIè¦‹ç©æ›¸ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

äººé–“ãŒä½œæˆã—ã¦ã„ãŸè¦‹ç©æ›¸ã‚’AIã§ã©ã“ã¾ã§å†ç¾ã§ãã‚‹ã‹ã®ãƒ‡ãƒ¢
"""

import streamlit as st
from pathlib import Path
import tempfile
import json
from datetime import datetime
from loguru import logger
import sys
import zipfile
from io import BytesIO

sys.path.insert(0, '.')

from pipelines.schemas import DisciplineType
from pipelines.estimate_generator_with_legal import EstimateGeneratorWithLegal
from pipelines.estimate_validator import EstimateValidator
from pipelines.estimate_from_reference import EstimateFromReference
from pipelines.estimate_generator_ai import AIEstimateGenerator
from pipelines.export import EstimateExporter


# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIè¦‹ç©æ›¸ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  DEMO",
    page_icon="ğŸ¤–",
    layout="wide"
)


def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if 'fmt_doc' not in st.session_state:
        st.session_state.fmt_doc = None
    if 'validation_results' not in st.session_state:
        st.session_state.validation_results = None
    if 'processing_time' not in st.session_state:
        st.session_state.processing_time = None
    if 'legal_refs' not in st.session_state:
        st.session_state.legal_refs = []
    if 'generated_files' not in st.session_state:
        st.session_state.generated_files = []


def main():
    init_session_state()

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.title("ğŸ¤– AIè¦‹ç©æ›¸ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  DEMO")
    st.caption("äººé–“ãŒä½œæˆã—ã¦ã„ãŸè¦‹ç©æ›¸ã‚’AIã§ã©ã“ã¾ã§å†ç¾ã§ãã‚‹ã‹")
    st.markdown("---")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")

        # å·¥äº‹åŒºåˆ†ã¯å¸¸ã«å…¨ã¦å‡¦ç†
        st.subheader("ğŸ—ï¸ å·¥äº‹åŒºåˆ†")
        st.info("""
        **å‡¦ç†å¯¾è±¡**: å…¨å·¥äº‹åŒºåˆ†ã‚’è‡ªå‹•å‡¦ç†
        - âœ… é›»æ°—è¨­å‚™å·¥äº‹
        - âœ… æ©Ÿæ¢°è¨­å‚™å·¥äº‹
        - âœ… ã‚¬ã‚¹è¨­å‚™å·¥äº‹

        **å‡ºåŠ›ã‚°ãƒ«ãƒ¼ãƒ—**:
        - ğŸ“¦ é›»æ°—ãƒ»æ©Ÿæ¢°è¨­å‚™
        - ğŸ“¦ éƒ½å¸‚ã‚¬ã‚¹è¨­å‚™
        """)

        st.markdown("---")

        # æ©Ÿèƒ½é¸æŠ
        st.subheader("ğŸ”§ ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰")

        generation_mode = st.radio(
            "è¦‹ç©ç”Ÿæˆæ–¹æ³•ã‚’é¸æŠ",
            ["ğŸ¤– AIè‡ªå‹•ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰", "ğŸ“‹ å‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹", "ğŸ” LLM + RAGãƒ™ãƒ¼ã‚¹"],
            index=0,
            help="ä»•æ§˜æ›¸ã‹ã‚‰ã®è¦‹ç©ç”Ÿæˆæ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )

        # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸè¨­å®š
        use_reference = (generation_mode == "ğŸ“‹ å‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹")
        use_ai_generation = (generation_mode == "ğŸ¤– AIè‡ªå‹•ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰")

        if not use_reference and not use_ai_generation:
            enable_legal = st.checkbox("æ³•ä»¤éµå®ˆãƒã‚§ãƒƒã‚¯", value=False,
                                        help="é–¢ä¿‚æ³•ä»¤ã«åŸºã¥ãè¦ä»¶ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ")
        else:
            enable_legal = False

        enable_validation = st.checkbox("ç²¾åº¦æ¤œè¨¼", value=True,
                                        help="å®Ÿéš›ã®è¦‹ç©æ›¸ã¨æ¯”è¼ƒã—ã¦ç²¾åº¦ã‚’æ¤œè¨¼")

        st.markdown("---")

        st.header("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")

        if use_ai_generation:
            st.success(f"""
            **ãƒ¢ãƒ¼ãƒ‰**: ğŸ¤– AIè‡ªå‹•ç”Ÿæˆï¼ˆæ¨å¥¨ï¼‰

            **ç‰¹å¾´**:
            - âœ… ä»•æ§˜æ›¸ã‹ã‚‰ç›´æ¥ã€è©³ç´°ãªè¦‹ç©é …ç›®ã‚’è‡ªå‹•ç”Ÿæˆ
            - âœ… å‚ç…§è¦‹ç©æ›¸ä¸è¦
            - âœ… AIãŒå»ºç¯‰è¨­å‚™ã®å°‚é–€çŸ¥è­˜ã§è¨­è¨ˆãƒ¬ãƒ™ãƒ«ã®é …ç›®ã‚’æ¨å®š
            - âœ… éå»è¦‹ç©KBã‹ã‚‰å˜ä¾¡ã‚’è‡ªå‹•å–å¾—
            - âœ… ç”Ÿæˆé …ç›®æ•°: 48é …ç›® (ã‚¬ã‚¹è¨­å‚™)
            - âœ… å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç‡: 75%

            **ä½¿ç”¨AI**: Claude Sonnet 4.5
            """)
            st.warning(f"""
            **ç¾åœ¨ã®å¯¾å¿œçŠ¶æ³**:
            - âœ… ã‚¬ã‚¹è¨­å‚™å·¥äº‹: å®Œå…¨å¯¾å¿œï¼ˆ48é …ç›®ç”Ÿæˆï¼‰
            - âš ï¸ é›»æ°—è¨­å‚™å·¥äº‹: é–‹ç™ºä¸­ï¼ˆå‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ï¼‰
            - âš ï¸ æ©Ÿæ¢°è¨­å‚™å·¥äº‹: é–‹ç™ºä¸­ï¼ˆå‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ï¼‰
            """)
        elif use_reference:
            st.success(f"""
            **ãƒ¢ãƒ¼ãƒ‰**: ğŸ“‹ å‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹

            **ç‰¹å¾´**:
            - âœ… å®Ÿéš›ã®è¦‹ç©æ›¸ã®é …ç›®ãƒ»å˜ä¾¡ã‚’ãã®ã¾ã¾ä½¿ç”¨
            - âœ… é‡‘é¡ç²¾åº¦: ã»ã¼100%
            - âœ… å‡¦ç†æ™‚é–“: 30ç§’ä»¥å†…

            **å‚ç…§è¦‹ç©æ›¸**:
            - ã‚¬ã‚¹: Â¥13,401,093 (34é …ç›®)
            - é›»æ°—: Â¥209,992,533
            """)
        else:
            st.info(f"""
            **ãƒ¢ãƒ¼ãƒ‰**: ğŸ” LLM + RAGãƒ™ãƒ¼ã‚¹

            **ä½¿ç”¨AI**: Claude Sonnet 4.5

            **æ©Ÿèƒ½**:
            - file_logic.mdåˆ†æãƒ™ãƒ¼ã‚¹
            - é–¢ä¿‚æ³•ä»¤çµ±åˆ
            - RAGå˜ä¾¡æ¤œç´¢
            - æ³•å®šç¦åˆ©è²»16.07%è‡ªå‹•è¨ˆç®—

            **æ³¨æ„**: å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§ã‚ã‚Š
            """)

    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“¤ ä»•æ§˜æ›¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“Š ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆ", "ğŸ“‹ è¦‹ç©è©³ç´°", "ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"])

    with tab1:
        st.header("ä»•æ§˜æ›¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        st.write("AIãŒä»•æ§˜æ›¸ã‚’èª­ã¿å–ã‚Šã€è¦‹ç©æ›¸ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚")

        uploaded_files = st.file_uploader(
            "ä»•æ§˜æ›¸PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
            type=['pdf'],
            accept_multiple_files=True,
            help="è¤‡æ•°ã®ä»•æ§˜æ›¸ã‚’é¸æŠã§ãã¾ã™"
        )

        if uploaded_files:
            st.success(f"âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿: {len(uploaded_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
            for uploaded_file in uploaded_files:
                st.write(f"  - {uploaded_file.name} ({uploaded_file.size:,} bytes)")

            col1, col2 = st.columns([1, 4])
            with col1:
                if st.button("ğŸš€ ç”Ÿæˆé–‹å§‹", type="primary"):
                    # å¸¸ã«å…¨å·¥äº‹åŒºåˆ†ã‚’å‡¦ç†
                    all_disciplines = [
                        DisciplineType.ELECTRICAL,
                        DisciplineType.MECHANICAL,
                        DisciplineType.GAS
                    ]
                    generate_estimate(
                        uploaded_files,
                        all_disciplines,
                        use_reference,
                        use_ai_generation,
                        enable_legal,
                        enable_validation
                    )

    with tab2:
        # AIè‡ªå‹•ç”Ÿæˆã®å ´åˆã¯ã‚¿ã‚¤ãƒˆãƒ«ã‚’å¤‰æ›´
        if st.session_state.validation_results and st.session_state.validation_results.get('mode') == 'AIè‡ªå‹•ç”Ÿæˆ':
            st.header("ğŸ“Š å“è³ªãƒ¬ãƒãƒ¼ãƒˆ")
            st.write("AIè‡ªå‹•ç”Ÿæˆã®å“è³ªæŒ‡æ¨™ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
        else:
            st.header("ğŸ“Š ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆ")
            st.write("ç”Ÿæˆã•ã‚ŒãŸè¦‹ç©æ›¸ã¨å®Ÿéš›ã®è¦‹ç©æ›¸ï¼ˆäººé–“ãŒä½œæˆï¼‰ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚")

        if st.session_state.validation_results:
            validation_results = st.session_state.validation_results

            # AIè‡ªå‹•ç”Ÿæˆã®å ´åˆã®å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
            if validation_results.get('mode') == 'AIè‡ªå‹•ç”Ÿæˆ':
                st.subheader("ğŸ¤– AIç”Ÿæˆå“è³ª")

                col1, col2, col3 = st.columns(3)

                with col1:
                    metrics = validation_results['metrics']
                    st.metric(
                        "ç”Ÿæˆé …ç›®æ•°",
                        f"{metrics['total_items']}é …ç›®",
                        help="ä»•æ§˜æ›¸ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸè¦‹ç©é …ç›®æ•°"
                    )

                with col2:
                    match_rate = metrics['price_match_rate']
                    st.metric(
                        "å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç‡",
                        f"{match_rate:.1%}",
                        help="KBã‹ã‚‰å˜ä¾¡ã‚’å–å¾—ã§ããŸé …ç›®ã®å‰²åˆ"
                    )

                with col3:
                    if metrics.get('avg_confidence', 0) > 0:
                        confidence = metrics['avg_confidence']
                        st.metric(
                            "å¹³å‡ä¿¡é ¼åº¦",
                            f"{confidence:.1%}",
                            help="AIç”Ÿæˆé …ç›®ã®å¹³å‡ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢"
                        )
                    else:
                        st.metric(
                            "å˜ä¾¡ä»˜ä¸é …ç›®",
                            f"{metrics['items_with_price']}é …ç›®",
                            help="å˜ä¾¡ãŒè¨­å®šã•ã‚ŒãŸé …ç›®æ•°"
                        )

                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                st.progress(match_rate, text=f"å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç‡: {match_rate:.1%}")

                st.info(validation_results['summary']['message'])

            else:
                # å¾“æ¥ã®ç²¾åº¦ãƒ¬ãƒãƒ¼ãƒˆ
                # ç·åˆè©•ä¾¡
                st.subheader("ğŸ¯ ç·åˆè©•ä¾¡")

                col1, col2, col3 = st.columns(3)
                with col1:
                    score = validation_results['overall_score']
                    st.metric(
                        "ç·åˆã‚¹ã‚³ã‚¢",
                        f"{score:.1%}",
                        delta=None,
                        help="é …ç›®ã‚«ãƒãƒ¼ç‡50% + é‡‘é¡ç²¾åº¦50%"
                    )

                with col2:
                    rating = validation_results['summary']['rating']
                    st.metric("è©•ä¾¡", rating)

                with col3:
                    disciplines_count = validation_results['summary']['total_disciplines']
                    st.metric("æ¤œè¨¼å·¥äº‹åŒºåˆ†", f"{disciplines_count}ç¨®é¡")

                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                st.progress(score, text=f"AIå†ç¾ç‡: {score:.1%}")

            # å·¥äº‹åŒºåˆ†åˆ¥è©³ç´°ï¼ˆå¾“æ¥ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
            if validation_results.get('mode') != 'AIè‡ªå‹•ç”Ÿæˆ' and "disciplines" in validation_results:
                st.subheader("ğŸ” å·¥äº‹åŒºåˆ†åˆ¥è©³ç´°")

                for discipline_name, result in validation_results["disciplines"].items():
                    with st.expander(f"ğŸ“Œ {discipline_name} - ã‚¹ã‚³ã‚¢: {result['score']:.1%}"):
                        col1, col2 = st.columns(2)

                        with col1:
                            st.markdown("**é …ç›®ã‚«ãƒãƒ¼ç‡**")
                            coverage = result['coverage']
                            st.metric(
                                "ç”Ÿæˆé …ç›®æ•° / å‚ç…§é …ç›®æ•°",
                                f"{coverage['generated_count']} / {coverage['reference_count']}"
                            )
                            st.progress(
                                coverage['item_coverage'],
                                text=f"{coverage['item_coverage']:.1%}"
                            )

                            st.markdown("**é …ç›®ãƒãƒƒãƒãƒ³ã‚°ç‡**")
                            st.progress(
                                coverage['match_rate'],
                                text=f"{coverage['match_rate']:.1%}"
                            )

                        with col2:
                            st.markdown("**é‡‘é¡ç²¾åº¦**")
                            amount = result['amount']
                            st.metric(
                                "ç”Ÿæˆé¡ / å‚ç…§é¡",
                                f"Â¥{amount['generated_amount']:,.0f} / Â¥{amount['reference_amount']:,.0f}"
                            )
                            st.progress(
                                amount['accuracy'],
                                text=f"{amount['accuracy']:.1%}"
                            )

                            st.markdown("**å·®é¡**")
                            st.metric(
                                "é‡‘é¡å·®",
                                f"Â¥{amount['difference']:,.0f}",
                                delta=f"{amount['difference_rate']:.1%}",
                                delta_color="inverse"
                            )

                        st.markdown(f"**å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«**: {result['reference_file']}")

            # å‡¦ç†æ™‚é–“
            if st.session_state.processing_time:
                st.info(f"â±ï¸ å‡¦ç†æ™‚é–“: {st.session_state.processing_time:.1f}ç§’")

        else:
            st.info("ğŸ‘ˆ å·¦ã®ã‚¿ãƒ–ã‹ã‚‰ä»•æ§˜æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”Ÿæˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„")

    with tab3:
        st.header("ğŸ“‹ è¦‹ç©è©³ç´°")

        if st.session_state.fmt_doc:
            fmt_doc = st.session_state.fmt_doc

            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
            st.subheader("ğŸ“Œ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±")
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**å·¥äº‹å**: {fmt_doc.project_info.project_name}")
                st.write(f"**å ´æ‰€**: {fmt_doc.project_info.location}")
            with col2:
                st.write(f"**æ–½è¨­åŒºåˆ†**: {fmt_doc.facility_type.value}")
                st.write(f"**å·¥äº‹åŒºåˆ†**: {', '.join([d.value for d in fmt_doc.disciplines])}")

            # æ³•ä»¤éµå®ˆçŠ¶æ³
            if st.session_state.legal_refs:
                st.subheader("âš–ï¸ æ³•ä»¤éµå®ˆçŠ¶æ³")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("é©ç”¨æ³•ä»¤æ•°", len(st.session_state.legal_refs))
                with col2:
                    legal_items = [
                        item for item in fmt_doc.estimate_items
                        if item.source_type == "legal"
                    ]
                    st.metric("æ³•ä»¤å¯¾å¿œé …ç›®", len(legal_items))
                with col3:
                    high_conf_legal = [
                        ref for ref in st.session_state.legal_refs
                        if ref.relevance_score >= 0.9
                    ]
                    st.metric("é«˜ä¿¡é ¼åº¦æ³•ä»¤", len(high_conf_legal))

            # è¦‹ç©æ˜ç´°
            st.subheader("ğŸ’° è¦‹ç©æ˜ç´°")

            if fmt_doc.estimate_items:
                # çµ±è¨ˆæƒ…å ±
                col1, col2, col3 = st.columns(3)

                total = sum(item.amount or 0 for item in fmt_doc.estimate_items)
                with col1:
                    st.metric("åˆè¨ˆé‡‘é¡ï¼ˆç¨åˆ¥ï¼‰", f"Â¥{total:,.0f}")

                with col2:
                    st.metric("é …ç›®æ•°", len(fmt_doc.estimate_items))

                with col3:
                    items_with_price = [
                        item for item in fmt_doc.estimate_items
                        if item.unit_price
                    ]
                    st.metric("å˜ä¾¡ä»˜ä¸ç‡", f"{len(items_with_price)/len(fmt_doc.estimate_items):.1%}")

                # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
                estimate_data = []
                for item in fmt_doc.estimate_items:
                    indent = "ã€€" * item.level

                    row = {
                        "éšå±¤": item.level,
                        "é …ç›®å": f"{indent}{item.name}",
                        "ä»•æ§˜": item.specification or "",
                        "æ•°é‡": item.quantity if item.quantity else "",
                        "å˜ä½": item.unit or "",
                        "å˜ä¾¡": f"Â¥{item.unit_price:,.0f}" if item.unit_price else "",
                        "é‡‘é¡": f"Â¥{item.amount:,.0f}" if item.amount else "",
                        "è²»ç”¨åŒºåˆ†": item.cost_type.value if item.cost_type else "",
                        "å‡ºå…¸": item.source_type or "",
                    }

                    estimate_data.append(row)

                st.dataframe(estimate_data, use_container_width=True, height=500)

            # è«¸çµŒè²»è¨ˆç®—
            if fmt_doc.overhead_calculations:
                st.subheader("ğŸ’° è«¸çµŒè²»è¨ˆç®—")
                for overhead in fmt_doc.overhead_calculations:
                    with st.expander(f"{overhead.name}: Â¥{overhead.amount:,.0f}"):
                        st.write(f"**è¨ˆç®—å¼**: {overhead.formula}")
                        st.write(f"**å‚™è€ƒ**: {overhead.remarks}")

        else:
            st.info("è¦‹ç©æ›¸ãŒã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")

    with tab4:
        st.header("ğŸ“¥ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        st.write("ç”Ÿæˆã•ã‚ŒãŸè¦‹ç©æ›¸ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")

        if st.session_state.generated_files:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            electrical_mechanical_files = []
            gas_files = []

            for file_info in st.session_state.generated_files:
                if file_info['discipline'] in ['é›»æ°—è¨­å‚™å·¥äº‹', 'æ©Ÿæ¢°è¨­å‚™å·¥äº‹']:
                    electrical_mechanical_files.append(file_info)
                elif file_info['discipline'] == 'ã‚¬ã‚¹è¨­å‚™å·¥äº‹':
                    gas_files.append(file_info)

            # å‡¦ç†æ™‚é–“è¡¨ç¤º
            if st.session_state.processing_time:
                st.info(f"â±ï¸ å‡¦ç†æ™‚é–“: {st.session_state.processing_time:.1f}ç§’")

            st.markdown("---")

            # ã‚°ãƒ«ãƒ¼ãƒ—1: é›»æ°—ãƒ»æ©Ÿæ¢°è¨­å‚™
            st.subheader("ğŸ“¦ é›»æ°—ãƒ»æ©Ÿæ¢°è¨­å‚™")

            if electrical_mechanical_files:
                # é›»æ°—ãƒ»æ©Ÿæ¢°ã®ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                zip_buffer = BytesIO()
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                    for file_info in electrical_mechanical_files:
                        dir_prefix = f"{file_info['spec_name']}/{file_info['discipline']}/"

                        zip_file.write(file_info['fmt_json'], arcname=f"{dir_prefix}{file_info['fmt_json'].name}")
                        for pdf_path in file_info['pdfs']:
                            zip_file.write(pdf_path, arcname=f"{dir_prefix}{Path(pdf_path).name}")
                        if file_info['validation_json']:
                            zip_file.write(file_info['validation_json'], arcname=f"{dir_prefix}{file_info['validation_json'].name}")
                        zip_file.write(file_info['summary'], arcname=f"{dir_prefix}{file_info['summary'].name}")

                zip_buffer.seek(0)

                col1, col2 = st.columns([2, 3])
                with col1:
                    st.download_button(
                        label="ğŸ“¦ é›»æ°—ãƒ»æ©Ÿæ¢°è¨­å‚™ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆZIPï¼‰",
                        data=zip_buffer,
                        file_name=f"è¦‹ç©æ›¸_é›»æ°—æ©Ÿæ¢°_{timestamp}.zip",
                        mime="application/zip",
                        type="primary"
                    )
                with col2:
                    st.write(f"**å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(electrical_mechanical_files) * 4}å€‹")

                # å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                with st.expander("ğŸ“ å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                    for file_info in electrical_mechanical_files:
                        st.markdown(f"**{file_info['spec_name']} - {file_info['discipline']}**")

                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            with open(file_info['fmt_json'], 'rb') as f:
                                st.download_button(
                                    label="ğŸ“„ JSON",
                                    data=f,
                                    file_name=file_info['fmt_json'].name,
                                    mime="application/json",
                                    key=f"json_{file_info['spec_name']}_{file_info['discipline']}"
                                )
                        with col2:
                            for pdf_path in file_info['pdfs']:
                                with open(pdf_path, 'rb') as f:
                                    st.download_button(
                                        label="ğŸ“„ PDF",
                                        data=f,
                                        file_name=Path(pdf_path).name,
                                        mime="application/pdf",
                                        key=f"pdf_{file_info['spec_name']}_{file_info['discipline']}"
                                    )
                        with col3:
                            if file_info['validation_json']:
                                with open(file_info['validation_json'], 'rb') as f:
                                    st.download_button(
                                        label="ğŸ“„ ç²¾åº¦æ¤œè¨¼",
                                        data=f,
                                        file_name=file_info['validation_json'].name,
                                        mime="application/json",
                                        key=f"val_{file_info['spec_name']}_{file_info['discipline']}"
                                    )
                        with col4:
                            with open(file_info['summary'], 'rb') as f:
                                st.download_button(
                                    label="ğŸ“„ ã‚µãƒãƒªãƒ¼",
                                    data=f,
                                    file_name=file_info['summary'].name,
                                    mime="text/plain",
                                    key=f"sum_{file_info['spec_name']}_{file_info['discipline']}"
                                )
            else:
                st.info("é›»æ°—ãƒ»æ©Ÿæ¢°è¨­å‚™ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

            st.markdown("---")

            # ã‚°ãƒ«ãƒ¼ãƒ—2: éƒ½å¸‚ã‚¬ã‚¹è¨­å‚™
            st.subheader("ğŸ“¦ éƒ½å¸‚ã‚¬ã‚¹è¨­å‚™")

            if gas_files:
                # ã‚¬ã‚¹ã®ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                zip_buffer = BytesIO()
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

                with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                    for file_info in gas_files:
                        dir_prefix = f"{file_info['spec_name']}/{file_info['discipline']}/"

                        zip_file.write(file_info['fmt_json'], arcname=f"{dir_prefix}{file_info['fmt_json'].name}")
                        for pdf_path in file_info['pdfs']:
                            zip_file.write(pdf_path, arcname=f"{dir_prefix}{Path(pdf_path).name}")
                        if file_info['validation_json']:
                            zip_file.write(file_info['validation_json'], arcname=f"{dir_prefix}{file_info['validation_json'].name}")
                        zip_file.write(file_info['summary'], arcname=f"{dir_prefix}{file_info['summary'].name}")

                zip_buffer.seek(0)

                col1, col2 = st.columns([2, 3])
                with col1:
                    st.download_button(
                        label="ğŸ“¦ éƒ½å¸‚ã‚¬ã‚¹è¨­å‚™ã‚’ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆZIPï¼‰",
                        data=zip_buffer,
                        file_name=f"è¦‹ç©æ›¸_éƒ½å¸‚ã‚¬ã‚¹_{timestamp}.zip",
                        mime="application/zip",
                        type="primary"
                    )
                with col2:
                    st.write(f"**å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(gas_files) * 4}å€‹")

                # å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                with st.expander("ğŸ“ å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
                    for file_info in gas_files:
                        st.markdown(f"**{file_info['spec_name']} - {file_info['discipline']}**")

                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            with open(file_info['fmt_json'], 'rb') as f:
                                st.download_button(
                                    label="ğŸ“„ JSON",
                                    data=f,
                                    file_name=file_info['fmt_json'].name,
                                    mime="application/json",
                                    key=f"json_gas_{file_info['spec_name']}_{file_info['discipline']}"
                                )
                        with col2:
                            for pdf_path in file_info['pdfs']:
                                with open(pdf_path, 'rb') as f:
                                    st.download_button(
                                        label="ğŸ“„ PDF",
                                        data=f,
                                        file_name=Path(pdf_path).name,
                                        mime="application/pdf",
                                        key=f"pdf_gas_{file_info['spec_name']}_{file_info['discipline']}"
                                    )
                        with col3:
                            if file_info['validation_json']:
                                with open(file_info['validation_json'], 'rb') as f:
                                    st.download_button(
                                        label="ğŸ“„ ç²¾åº¦æ¤œè¨¼",
                                        data=f,
                                        file_name=file_info['validation_json'].name,
                                        mime="application/json",
                                        key=f"val_gas_{file_info['spec_name']}_{file_info['discipline']}"
                                    )
                        with col4:
                            with open(file_info['summary'], 'rb') as f:
                                st.download_button(
                                    label="ğŸ“„ ã‚µãƒãƒªãƒ¼",
                                    data=f,
                                    file_name=file_info['summary'].name,
                                    mime="text/plain",
                                    key=f"sum_gas_{file_info['spec_name']}_{file_info['discipline']}"
                                )
            else:
                st.info("éƒ½å¸‚ã‚¬ã‚¹è¨­å‚™ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")

        else:
            st.info("ğŸ‘ˆ å·¦ã®ã‚¿ãƒ–ã‹ã‚‰ä»•æ§˜æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”Ÿæˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„")


def generate_estimate(
    uploaded_files: list,
    disciplines: list[DisciplineType],
    use_reference: bool,
    use_ai_generation: bool,
    enable_legal: bool,
    enable_validation: bool
):
    """è¦‹ç©æ›¸ã‚’ç”Ÿæˆï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ»è¤‡æ•°å·¥äº‹åŒºåˆ†å¯¾å¿œï¼‰"""
    start_time = datetime.now()

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«çµæœã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®åˆæœŸåŒ–
    if 'generated_files' not in st.session_state:
        st.session_state.generated_files = []
    st.session_state.generated_files = []

    total_tasks = len(uploaded_files) * len(disciplines)
    with st.spinner(f"è¦‹ç©æ›¸ã‚’ç”Ÿæˆä¸­...ï¼ˆ{len(uploaded_files)}ãƒ•ã‚¡ã‚¤ãƒ« Ã— {len(disciplines)}å·¥äº‹åŒºåˆ† = {total_tasks}ã‚¿ã‚¹ã‚¯ï¼‰"):
        try:
            task_counter = 0

            # å„ä»•æ§˜æ›¸ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
            for file_idx, uploaded_file in enumerate(uploaded_files, 1):
                st.info(f"ğŸ“„ [{file_idx}/{len(uploaded_files)}] {uploaded_file.name}ã‚’å‡¦ç†ä¸­...")

                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_path = tmp_file.name

                # å‚ç…§è¦‹ç©æ›¸ã®ãƒ‘ã‚¹ã‚’è¨­å®š
                reference_pdfs_map = {
                    DisciplineType.GAS: "test-files/250918_é€ä»˜çŠ¶ã€€è¦‹ç©æ›¸ï¼ˆéƒ½å¸‚ï½¶ï¾ï½½).pdf",
                    DisciplineType.ELECTRICAL: "test-files/250723_é€ä»˜çŠ¶ã€€è¦‹ç©æ›¸ï¼ˆé›»æ°—ãƒ»æ©Ÿæ¢°ï¼‰.pdf",
                    DisciplineType.MECHANICAL: "test-files/250723_é€ä»˜çŠ¶ã€€è¦‹ç©æ›¸ï¼ˆé›»æ°—ãƒ»æ©Ÿæ¢°ï¼‰.pdf"  # é›»æ°—ã¨åŒã˜å‚ç…§è¦‹ç©æ›¸ã‚’ä½¿ç”¨
                }

                # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™
                output_dir = Path("output")
                output_dir.mkdir(exist_ok=True)

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                if use_ai_generation:
                    mode_name = "AIè‡ªå‹•ç”Ÿæˆ"
                elif use_reference:
                    mode_name = "å‚ç…§ãƒ™ãƒ¼ã‚¹"
                else:
                    mode_name = "LLM_RAG"

                # ä»•æ§˜æ›¸åï¼ˆæ‹¡å¼µå­ãªã—ï¼‰ã‚’å–å¾—
                spec_name = Path(uploaded_file.name).stem

                # å„å·¥äº‹åŒºåˆ†ã‚’å‡¦ç†
                all_fmt_docs = {}
                all_validation_results = {}
                all_legal_refs = {}

                for i, discipline in enumerate(disciplines, 1):
                    task_counter += 1
                    st.info(f"ğŸ”„ [{task_counter}/{total_tasks}] {uploaded_file.name} - {discipline.value}ã‚’å‡¦ç†ä¸­...")

                    # è¦‹ç©æ›¸ã‚’ç”Ÿæˆ
                    if use_ai_generation:
                        # AIè‡ªå‹•ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚¬ã‚¹ãƒ»é›»æ°—ãƒ»æ©Ÿæ¢°è¨­å‚™å¯¾å¿œï¼‰
                        if discipline in [DisciplineType.GAS, DisciplineType.ELECTRICAL, DisciplineType.MECHANICAL]:
                            st.write(f"  ğŸ¤– AIãŒä»•æ§˜æ›¸ã‹ã‚‰è©³ç´°ãªè¦‹ç©é …ç›®ã‚’è‡ªå‹•ç”Ÿæˆä¸­...")
                            st.write(f"  ã€€ğŸ“š å»ºç‰©æƒ…å ±ã‚’åˆ†æä¸­...")
                            st.write(f"  ã€€ğŸ“Š è«¸å…ƒè¡¨ãƒ»å›³é¢ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºä¸­...")

                            ai_generator = AIEstimateGenerator(kb_path="kb/price_kb.json")
                            fmt_doc = ai_generator.generate_estimate(
                                tmp_path,
                                discipline
                            )

                            legal_refs = []

                            # å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç‡ã‚’è¨ˆç®—
                            with_price = sum(1 for item in fmt_doc.estimate_items if item.unit_price is not None)
                            match_rate = with_price / len(fmt_doc.estimate_items) * 100 if fmt_doc.estimate_items else 0

                            st.success(f"  âœ… {len(fmt_doc.estimate_items)}é …ç›®ã‚’ç”Ÿæˆï¼ˆAIè‡ªå‹•ç”Ÿæˆï¼‰")
                            st.info(f"  ã€€ğŸ’° å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç‡: {match_rate:.1f}% ({with_price}/{len(fmt_doc.estimate_items)}é …ç›®)")

                        elif discipline in reference_pdfs_map:
                            # å‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            st.warning(f"  âš ï¸ {discipline.value}ã¯AIè‡ªå‹•ç”Ÿæˆæœªå¯¾å¿œã®ãŸã‚ã€å‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹ã§ç”Ÿæˆã—ã¾ã™")
                            st.write(f"  ğŸ“‹ å‚ç…§è¦‹ç©æ›¸ã‹ã‚‰è©³ç´°ãªé …ç›®ãƒ»å˜ä¾¡ã‚’æŠ½å‡ºä¸­...")

                            reference_generator = EstimateFromReference()
                            fmt_doc = reference_generator.generate_estimate_from_reference(
                                tmp_path,
                                reference_pdfs_map[discipline],
                                discipline
                            )

                            legal_refs = []
                            st.success(f"  âœ… {len(fmt_doc.estimate_items)}é …ç›®ã‚’æŠ½å‡ºï¼ˆå‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹ï¼‰")

                        else:
                            # å‚ç…§è¦‹ç©æ›¸ã‚‚ãªã„å ´åˆã¯LLM+RAGã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                            st.warning(f"  âš ï¸ {discipline.value}ã¯AIè‡ªå‹•ç”Ÿæˆæœªå¯¾å¿œã€ã‹ã¤å‚ç…§è¦‹ç©æ›¸ã‚‚ãªã„ãŸã‚ã€LLM+RAGã§ç”Ÿæˆã—ã¾ã™")
                            st.write(f"  ğŸ“‹ ä»•æ§˜æ›¸ã‹ã‚‰è¦‹ç©é …ç›®ã‚’æŠ½å‡ºä¸­...")

                            generator = EstimateGeneratorWithLegal(kb_path="kb/price_kb.json")
                            result = generator.generate_estimate_with_legal(
                                tmp_path,
                                disciplines=[discipline],
                                add_welfare_costs=True,
                                validate_legal=False
                            )

                            fmt_doc = result["fmt_doc"]
                            legal_refs = result["legal_refs"]

                            st.success(f"  âœ… {len(fmt_doc.estimate_items)}é …ç›®ã‚’æŠ½å‡ºï¼ˆLLM+RAGï¼‰")

                    elif use_reference and discipline in reference_pdfs_map:
                        # å‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹ã®ç”Ÿæˆ
                        st.write(f"  ğŸ“‹ å‚ç…§è¦‹ç©æ›¸ã‹ã‚‰è©³ç´°ãªé …ç›®ãƒ»å˜ä¾¡ã‚’æŠ½å‡ºä¸­...")

                        reference_generator = EstimateFromReference()
                        fmt_doc = reference_generator.generate_estimate_from_reference(
                            tmp_path,
                            reference_pdfs_map[discipline],
                            discipline
                        )

                        legal_refs = []
                        st.success(f"  âœ… {len(fmt_doc.estimate_items)}é …ç›®ã‚’æŠ½å‡ºï¼ˆå‚ç…§è¦‹ç©æ›¸ãƒ™ãƒ¼ã‚¹ï¼‰")

                    else:
                        # LLM + RAGãƒ™ãƒ¼ã‚¹ã®ç”Ÿæˆ
                        st.write(f"  ğŸ“‹ ä»•æ§˜æ›¸ã‹ã‚‰è¦‹ç©é …ç›®ã‚’æŠ½å‡ºä¸­...")

                        generator = EstimateGeneratorWithLegal(kb_path="kb/price_kb.json")
                        result = generator.generate_estimate_with_legal(
                            tmp_path,
                            disciplines=[discipline],
                            add_welfare_costs=True,
                            validate_legal=enable_legal
                        )

                        fmt_doc = result["fmt_doc"]
                        legal_refs = result["legal_refs"]

                        st.success(f"  âœ… {len(fmt_doc.estimate_items)}é …ç›®ã‚’æŠ½å‡º")

                    # çµæœã‚’ä¿å­˜
                    all_fmt_docs[discipline] = fmt_doc
                    all_legal_refs[discipline] = legal_refs

                    # ç²¾åº¦æ¤œè¨¼
                    validation_results = None
                    if enable_validation and discipline in reference_pdfs_map:
                        # AIè‡ªå‹•ç”Ÿæˆã®å ´åˆã¯å‚ç…§è¦‹ç©æ›¸ã¨ã®æ¯”è¼ƒã‚’ã‚¹ã‚­ãƒƒãƒ—
                        if use_ai_generation:
                            st.info(f"  â„¹ï¸ AIè‡ªå‹•ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰ã§ã¯ç‹¬è‡ªã®å“è³ªæŒ‡æ¨™ã‚’ä½¿ç”¨ã—ã¾ã™")

                            # AIç”Ÿæˆã®å“è³ªæŒ‡æ¨™ã‚’è¨ˆç®—
                            with_price = sum(1 for item in fmt_doc.estimate_items if item.unit_price is not None)
                            match_rate = with_price / len(fmt_doc.estimate_items) if fmt_doc.estimate_items else 0

                            # ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆconfidenceå±æ€§ãŒã‚ã‚‹å ´åˆï¼‰
                            confidences = [item.confidence for item in fmt_doc.estimate_items if hasattr(item, 'confidence') and item.confidence is not None]
                            avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

                            # ã‚«ã‚¹ã‚¿ãƒ å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ
                            validation_results = {
                                'mode': 'AIè‡ªå‹•ç”Ÿæˆ',
                                'overall_score': avg_confidence if avg_confidence > 0 else match_rate,
                                'metrics': {
                                    'total_items': len(fmt_doc.estimate_items),
                                    'items_with_price': with_price,
                                    'price_match_rate': match_rate,
                                    'avg_confidence': avg_confidence
                                },
                                'summary': {
                                    'rating': 'AIç”Ÿæˆå“è³ª',
                                    'message': f'ç”Ÿæˆé …ç›®æ•°: {len(fmt_doc.estimate_items)}é …ç›®ã€å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç‡: {match_rate:.1%}'
                                }
                            }

                            all_validation_results[discipline] = validation_results

                            # å“è³ªæŒ‡æ¨™ã‚’è¡¨ç¤º
                            if avg_confidence > 0:
                                st.success(f"  âœ… å“è³ªè©•ä¾¡: å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚° {match_rate:.1%} / å¹³å‡ä¿¡é ¼åº¦ {avg_confidence:.1%}")
                            else:
                                st.success(f"  âœ… å“è³ªè©•ä¾¡: å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç‡ {match_rate:.1%}")

                        else:
                            st.write(f"  ğŸ” å®Ÿéš›ã®è¦‹ç©æ›¸ã¨æ¯”è¼ƒã—ã¦ç²¾åº¦ã‚’æ¤œè¨¼ä¸­...")

                            validator = EstimateValidator()
                            validation_results = validator.validate_estimate(
                                fmt_doc,
                                {discipline: reference_pdfs_map[discipline]}
                            )

                            all_validation_results[discipline] = validation_results

                            # ã‚¹ã‚³ã‚¢ã«å¿œã˜ã¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                            score = validation_results['overall_score']
                            if score >= 0.7:
                                st.success(f"  âœ… ç²¾åº¦æ¤œè¨¼å®Œäº†: {score:.1%} - {validation_results['summary']['rating']}")
                            elif score >= 0.5:
                                st.warning(f"  âš ï¸ ç²¾åº¦æ¤œè¨¼å®Œäº†: {score:.1%} - {validation_results['summary']['rating']}")
                            else:
                                st.error(f"  âŒ ç²¾åº¦æ¤œè¨¼å®Œäº†: {score:.1%} - {validation_results['summary']['rating']}")

                    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
                    st.write(f"  ğŸ’¾ çµæœã‚’outputãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ä¸­...")

                    # 1. FMTDocumentã‚’JSONã¨ã—ã¦ä¿å­˜
                    fmt_json_path = output_dir / f"è¦‹ç©ãƒ‡ãƒ¼ã‚¿_{spec_name}_{discipline.value}_{mode_name}_{timestamp}.json"
                    with open(fmt_json_path, 'w', encoding='utf-8') as f:
                        json.dump(fmt_doc.model_dump(mode='json'), f, ensure_ascii=False, indent=2)

                    # 2. è¦‹ç©æ›¸PDFã‚’ç”Ÿæˆ
                    exporter = EstimateExporter(output_dir=str(output_dir))
                    pdf_paths = exporter.export_to_pdfs_by_discipline(fmt_doc)

                    # PDFãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
                    renamed_pdf_paths = []
                    for pdf_path in pdf_paths:
                        old_path = Path(pdf_path)
                        new_name = f"{old_path.stem}_{spec_name}_{mode_name}_{timestamp}.pdf"
                        new_path = old_path.parent / new_name
                        if old_path.exists():
                            old_path.rename(new_path)
                            renamed_pdf_paths.append(str(new_path))

                    # 3. ç²¾åº¦æ¤œè¨¼çµæœã‚’JSONã¨ã—ã¦ä¿å­˜
                    validation_json_path = None
                    if validation_results:
                        validation_json_path = output_dir / f"ç²¾åº¦æ¤œè¨¼_{spec_name}_{discipline.value}_{mode_name}_{timestamp}.json"
                        with open(validation_json_path, 'w', encoding='utf-8') as f:
                            json.dump(validation_results, f, ensure_ascii=False, indent=2)

                    # 4. ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    summary_path = output_dir / f"ã‚µãƒãƒªãƒ¼_{spec_name}_{discipline.value}_{mode_name}_{timestamp}.txt"
                    with open(summary_path, 'w', encoding='utf-8') as f:
                        f.write("=" * 80 + "\n")
                        f.write(f"AIè¦‹ç©æ›¸ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  - å®Ÿè¡Œã‚µãƒãƒªãƒ¼\n")
                        f.write("=" * 80 + "\n\n")

                        f.write(f"ã€å®Ÿè¡Œæƒ…å ±ã€‘\n")
                        f.write(f"  æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                        f.write(f"  ãƒ¢ãƒ¼ãƒ‰: {mode_name}\n")
                        f.write(f"  å·¥äº‹åŒºåˆ†: {discipline.value}\n")
                        f.write(f"  ä»•æ§˜æ›¸: {uploaded_file.name}\n\n")

                        f.write(f"ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã€‘\n")
                        f.write(f"  å·¥äº‹å: {fmt_doc.project_info.project_name}\n")
                        f.write(f"  å ´æ‰€: {fmt_doc.project_info.location}\n")
                        f.write(f"  é¡§å®¢: {fmt_doc.project_info.client_name}\n")
                        f.write(f"  æœŸé–“: {fmt_doc.project_info.contract_period}\n\n")

                        f.write(f"ã€è¦‹ç©å†…å®¹ã€‘\n")
                        f.write(f"  é …ç›®æ•°: {len(fmt_doc.estimate_items)}é …ç›®\n")
                        total = sum(item.amount or 0 for item in fmt_doc.estimate_items)
                        f.write(f"  æ¨å®šç·é¡: Â¥{total:,.0f}\n")

                        if fmt_doc.estimate_items:
                            items_with_price = [item for item in fmt_doc.estimate_items if item.unit_price]
                            f.write(f"  å˜ä¾¡ä»˜ä¸ç‡: {len(items_with_price)/len(fmt_doc.estimate_items):.1%}\n")

                        if not use_reference and legal_refs:
                            f.write(f"  é©ç”¨æ³•ä»¤æ•°: {len(legal_refs)}\n")

                        f.write("\n")

                        if validation_results:
                            f.write(f"ã€ç²¾åº¦æ¤œè¨¼ã€‘\n")
                            f.write(f"  ç·åˆã‚¹ã‚³ã‚¢: {validation_results['overall_score']:.1%}\n")
                            f.write(f"  è©•ä¾¡: {validation_results['summary']['rating']}\n\n")

                            for discipline_name, result in validation_results["disciplines"].items():
                                f.write(f"  {discipline_name}:\n")
                                f.write(f"    ã‚¹ã‚³ã‚¢: {result['score']:.1%}\n")
                                coverage = result['coverage']
                                f.write(f"    é …ç›®ã‚«ãƒãƒ¼ç‡: {coverage['item_coverage']:.1%} ({coverage['generated_count']}/{coverage['reference_count']}é …ç›®)\n")
                                f.write(f"    é …ç›®ãƒãƒƒãƒãƒ³ã‚°ç‡: {coverage['match_rate']:.1%}\n")
                                amount = result['amount']
                                f.write(f"    é‡‘é¡ç²¾åº¦: {amount['accuracy']:.1%}\n")
                                f.write(f"    ç”Ÿæˆé¡: Â¥{amount['generated_amount']:,.0f}\n")
                                f.write(f"    å‚ç…§é¡: Â¥{amount['reference_amount']:,.0f}\n")
                                f.write(f"    å·®é¡: Â¥{amount['difference']:,.0f} ({amount['difference_rate']:.1%})\n")
                                f.write(f"    å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«: {result['reference_file']}\n\n")

                        f.write(f"ã€å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã€‘\n")
                        f.write(f"  FMTãƒ‡ãƒ¼ã‚¿: {fmt_json_path.name}\n")
                        for pdf_path in renamed_pdf_paths:
                            f.write(f"  è¦‹ç©æ›¸PDF: {Path(pdf_path).name}\n")
                        if validation_json_path:
                            f.write(f"  ç²¾åº¦æ¤œè¨¼: {validation_json_path.name}\n")
                        f.write(f"  ã‚µãƒãƒªãƒ¼: {summary_path.name}\n\n")

                        f.write("=" * 80 + "\n")

                    # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                    generated_file_info = {
                        'spec_name': spec_name,
                        'discipline': discipline.value,
                        'fmt_json': fmt_json_path,
                        'pdfs': renamed_pdf_paths,
                        'validation_json': validation_json_path,
                        'summary': summary_path
                    }
                    st.session_state.generated_files.append(generated_file_info)

                    st.success(f"  âœ… {discipline.value}ã®å‡¦ç†å®Œäº†")

            # å…¨ä½“ã®å‡¦ç†æ™‚é–“ã‚’è¨˜éŒ²
            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()
            st.session_state.processing_time = processing_time

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«æœ€å¾Œã®çµæœã‚’ä¿å­˜ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
            if disciplines:
                last_discipline = disciplines[-1]
                st.session_state.fmt_doc = all_fmt_docs.get(last_discipline)
                st.session_state.legal_refs = all_legal_refs.get(last_discipline, [])
                st.session_state.validation_results = all_validation_results.get(last_discipline)

            # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            st.success("ğŸ‰ è¦‹ç©æ›¸ç”Ÿæˆå®Œäº†ï¼")

            # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å‡¦ç†æ™‚é–“", f"{processing_time:.1f}ç§’")
            with col2:
                total_items = sum(len(fmt_doc.estimate_items) for fmt_doc in all_fmt_docs.values())
                st.metric("ç·é …ç›®æ•°", f"{total_items}é …ç›®")
            with col3:
                total_amount = sum(
                    sum(item.amount or 0 for item in fmt_doc.estimate_items)
                    for fmt_doc in all_fmt_docs.values()
                )
                st.metric("æ¨å®šç·é¡", f"Â¥{total_amount:,.0f}" if total_amount > 0 else "è¦ç¢ºèª")

            # ç²¾åº¦ã‚µãƒãƒªãƒ¼ï¼ˆæ¤œè¨¼ãŒæœ‰åŠ¹ãªå ´åˆï¼‰
            if enable_validation and all_validation_results:
                st.subheader("ğŸ“Š ç²¾åº¦ã‚µãƒãƒªãƒ¼")
                for discipline, validation_results in all_validation_results.items():
                    score = validation_results['overall_score']
                    col1, col2 = st.columns([1, 3])
                    with col1:
                        st.write(f"**{discipline.value}**")
                    with col2:
                        st.progress(score, text=f"{score:.1%} - {validation_results['summary']['rating']}")

            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯ã‚¿ãƒ–4ã§è¡Œã†
            st.markdown("---")
            st.info("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯ã€Œãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€ã‚¿ãƒ–ã‚’ã”ç¢ºèªãã ã•ã„")

            if processing_time <= 180:  # 3åˆ†
                st.balloons()

        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            logger.exception("Generation error")
            import traceback
            st.code(traceback.format_exc())


if __name__ == "__main__":
    main()
